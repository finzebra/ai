{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy matplotlib Pillow requests"
      ],
      "metadata": {
        "id": "lbh6uDgzb95c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Import Necessary Libraries ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import copy # To ensure model 2 is a separate instance\n",
        "import matplotlib.pyplot as plt # Import for displaying images\n",
        "\n",
        "# === Configuration ===\n",
        "# Use GPU if available in Colab, otherwise CPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"--- Using device: {DEVICE} ---\")\n",
        "\n",
        "# Epsilon: Controls the magnitude of the noise added.\n",
        "EPSILON = 0.02 # You can experiment with this value (e.g., 0.01, 0.05)\n",
        "\n",
        "# ImageNet class labels (fetch if not present)\n",
        "LABELS_URL = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
        "LABELS_PATH = \"/content/imagenet-simple-labels.json\" # Standard Colab path\n",
        "\n",
        "# Royalty-Free Sample image URL (Labrador from PyTorch Hub repo)\n",
        "IMAGE_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg\"\n",
        "# Define explicit paths for saving in Colab's temporary storage\n",
        "ORIGINAL_IMAGE_SAVE_PATH = \"/content/original_image.png\"\n",
        "NOISE_IMAGE_SAVE_PATH = \"/content/noise_visualization.png\"\n",
        "ADVERSARIAL_IMAGE_SAVE_PATH = \"/content/adversarial_image.png\"\n",
        "\n",
        "# === Helper Functions ===\n",
        "\n",
        "def get_imagenet_labels():\n",
        "    \"\"\"Downloads or loads ImageNet labels.\"\"\"\n",
        "    if not os.path.exists(LABELS_PATH):\n",
        "        print(\"Downloading ImageNet labels...\")\n",
        "        response = requests.get(LABELS_URL)\n",
        "        response.raise_for_status()\n",
        "        with open(LABELS_PATH, 'w') as f:\n",
        "            f.write(response.text)\n",
        "        print(f\"Labels saved to {LABELS_PATH}\")\n",
        "    with open(LABELS_PATH) as f:\n",
        "        labels = json.load(f)\n",
        "    return labels\n",
        "\n",
        "def download_and_load_image(url, save_path):\n",
        "    \"\"\"Downloads an image, saves it, and loads it as PIL.\"\"\"\n",
        "    if not os.path.exists(save_path):\n",
        "        print(f\"Downloading image from {url}...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(save_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"Original image downloaded and saved to {save_path}\")\n",
        "    else:\n",
        "        print(f\"Original image {save_path} already exists.\")\n",
        "    # Load the saved image using PIL\n",
        "    img_pil = Image.open(save_path).convert('RGB')\n",
        "    return img_pil\n",
        "\n",
        "def preprocess_pil_image(img_pil):\n",
        "    \"\"\"Preprocesses a PIL image for ResNet.\"\"\"\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    img_t = preprocess(img_pil)\n",
        "    batch_t = torch.unsqueeze(img_t, 0) # Add batch dimension\n",
        "    return batch_t.to(DEVICE)\n",
        "\n",
        "def deprocess_tensor_to_pil(tensor):\n",
        "    \"\"\"Converts a normalized tensor back to a PIL Image.\"\"\"\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    tensor = tensor.squeeze(0).cpu().detach().numpy()\n",
        "    tensor = tensor.transpose(1, 2, 0)\n",
        "    tensor = std * tensor + mean\n",
        "    tensor = np.clip(tensor, 0, 1)\n",
        "    # Convert float [0,1] to uint8 [0,255]\n",
        "    img_pil = Image.fromarray((tensor * 255).astype(np.uint8))\n",
        "    return img_pil\n",
        "\n",
        "def save_pil_image(img_pil, filename):\n",
        "    \"\"\"Saves a PIL image object to a file.\"\"\"\n",
        "    try:\n",
        "        img_pil.save(filename)\n",
        "        print(f\"Image successfully saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving image {filename}: {e}\")\n",
        "\n",
        "\n",
        "def fgsm_attack(model, loss_fn, image, epsilon, target_label):\n",
        "    \"\"\"Performs the Fast Gradient Sign Method attack.\"\"\"\n",
        "    image.requires_grad = True\n",
        "    output = model(image)\n",
        "    loss = loss_fn(output, target_label)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    gradient = image.grad.data\n",
        "    sign_gradient = gradient.sign()\n",
        "    perturbed_image = image + epsilon * sign_gradient\n",
        "    perturbed_image = perturbed_image.detach()\n",
        "    image.requires_grad = False # Clean up\n",
        "    return perturbed_image, sign_gradient\n",
        "\n",
        "# === Main Execution ===\n",
        "\n",
        "print(\"\\n--- Starting Adversarial Attack Experiment ---\")\n",
        "\n",
        "# 1. Setup: Load labels and download/save/load sample image\n",
        "imagenet_labels = get_imagenet_labels()\n",
        "# Download if needed, and load the original PIL image\n",
        "original_pil_image = download_and_load_image(IMAGE_URL, ORIGINAL_IMAGE_SAVE_PATH)\n",
        "# Save the original image again (or confirm it was saved) - Redundant if download_and_load_image saves it.\n",
        "# save_pil_image(original_pil_image, ORIGINAL_IMAGE_SAVE_PATH) # Already saved in helper\n",
        "\n",
        "\n",
        "# 2. Load the first pre-trained model (Attacker's view / Generator)\n",
        "print(\"\\n--- Loading Model 1 (for attack generation) ---\")\n",
        "model1 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model1.eval()\n",
        "model1.to(DEVICE)\n",
        "\n",
        "# 3. Preprocess the original image for Model 1\n",
        "original_image_tensor = preprocess_pil_image(original_pil_image)\n",
        "\n",
        "# 4. Get the original prediction using Model 1\n",
        "print(\"\\n--- Classifying Original Image with Model 1 ---\")\n",
        "with torch.no_grad():\n",
        "    output1_orig = model1(original_image_tensor)\n",
        "\n",
        "original_prob = torch.nn.functional.softmax(output1_orig, dim=1)\n",
        "original_pred_prob, original_pred_idx = torch.max(original_prob, 1)\n",
        "original_pred_label = imagenet_labels[original_pred_idx.item()]\n",
        "\n",
        "print(f\"Model 1 Original Prediction: '{original_pred_label}' (Index: {original_pred_idx.item()})\")\n",
        "print(f\"Confidence: {original_pred_prob.item():.4f}\")\n",
        "\n",
        "# 5. Generate the adversarial example using FGSM\n",
        "print(f\"\\n--- Generating Adversarial Example (FGSM, Epsilon={EPSILON}) ---\")\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "target = original_pred_idx\n",
        "\n",
        "adversarial_image_tensor, noise_sign_tensor = fgsm_attack(\n",
        "    model1, loss_function, original_image_tensor.clone(), EPSILON, target\n",
        ")\n",
        "\n",
        "# 6. Prepare Adversarial Image & Noise Visualization for saving/display\n",
        "print(\"\\n--- Preparing & Saving Adversarial Results ---\")\n",
        "# Adversarial Image (PIL format)\n",
        "adversarial_pil_image = deprocess_tensor_to_pil(adversarial_image_tensor)\n",
        "save_pil_image(adversarial_pil_image, ADVERSARIAL_IMAGE_SAVE_PATH)\n",
        "\n",
        "# Noise Visualization (PIL format)\n",
        "noise_vis_tensor = noise_sign_tensor.squeeze(0).cpu()\n",
        "noise_vis_tensor = (noise_vis_tensor + 1) / 2 # Scale sign {-1, 1} to {0, 1}\n",
        "noise_pil_image = transforms.ToPILImage()(noise_vis_tensor)\n",
        "save_pil_image(noise_pil_image, NOISE_IMAGE_SAVE_PATH)\n",
        "\n",
        "# 7. Load the second pre-trained model (Victim's view / Classifier)\n",
        "print(\"\\n--- Loading Model 2 (for classifying adversarial image) ---\")\n",
        "model2 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model2.eval()\n",
        "model2.to(DEVICE)\n",
        "\n",
        "# 8. Load the *saved* adversarial image and preprocess it for Model 2\n",
        "print(f\"\\n--- Loading Adversarial Image from {ADVERSARIAL_IMAGE_SAVE_PATH} ---\")\n",
        "# We use the already generated 'adversarial_pil_image' for consistency before display\n",
        "# but simulate the loading process for classification tensor\n",
        "adversarial_pil_loaded = Image.open(ADVERSARIAL_IMAGE_SAVE_PATH).convert('RGB')\n",
        "adversarial_image_loaded_tensor = preprocess_pil_image(adversarial_pil_loaded)\n",
        "\n",
        "# 9. Classify the adversarial image using Model 2\n",
        "print(\"\\n--- Classifying Adversarial Image with Model 2 ---\")\n",
        "with torch.no_grad():\n",
        "    output2_adv = model2(adversarial_image_loaded_tensor)\n",
        "\n",
        "adv_prob = torch.nn.functional.softmax(output2_adv, dim=1)\n",
        "adv_pred_prob, adv_pred_idx = torch.max(adv_prob, 1)\n",
        "adv_pred_label = imagenet_labels[adv_pred_idx.item()]\n",
        "\n",
        "print(f\"Model 2 Adversarial Prediction: '{adv_pred_label}' (Index: {adv_pred_idx.item()})\")\n",
        "print(f\"Confidence: {adv_pred_prob.item():.4f}\")\n",
        "if original_pred_idx.item() != adv_pred_idx.item():\n",
        "    print(\">>> Attack Successful: Model 2 misclassified the adversarial image! <<<\")\n",
        "else:\n",
        "    print(\">>> Attack Unsuccessful: Model 2 correctly classified the adversarial image. (Try increasing Epsilon?) <<<\")\n",
        "\n",
        "\n",
        "# 10. Display Images in Colab Output\n",
        "print(\"\\n--- Displaying Images ---\")\n",
        "\n",
        "plt.figure(figsize=(18, 6)) # Adjusted figure size for better layout\n",
        "\n",
        "# Subplot 1: Original Image\n",
        "plt.subplot(1, 3, 1)\n",
        "# Convert PIL to NumPy array for imshow\n",
        "plt.imshow(np.array(original_pil_image))\n",
        "plt.title(f\"Original Image\\nPred (M1): '{original_pred_label}'\\n({original_pred_prob.item()*100:.2f}%)\", fontsize=10)\n",
        "plt.axis('off')\n",
        "\n",
        "# Subplot 2: Noise Visualization\n",
        "plt.subplot(1, 3, 2)\n",
        "# Convert PIL to NumPy array for imshow\n",
        "plt.imshow(np.array(noise_pil_image))\n",
        "plt.title(f\"Noise Visualization\\n(FGSM Sign Gradient, eps={EPSILON})\", fontsize=10)\n",
        "plt.axis('off')\n",
        "\n",
        "# Subplot 3: Adversarial Image\n",
        "plt.subplot(1, 3, 3)\n",
        "# Convert PIL to NumPy array for imshow\n",
        "plt.imshow(np.array(adversarial_pil_image))\n",
        "plt.title(f\"Adversarial Image\\nPred (M2): '{adv_pred_label}'\\n({adv_pred_prob.item()*100:.2f}%)\", fontsize=10)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlap\n",
        "plt.show() # Display the plots inline\n",
        "\n",
        "\n",
        "# 11. Final Summary in Terminal\n",
        "print(\"\\n--- Experiment Summary ---\")\n",
        "print(f\"Original Image Prediction (Model 1): '{original_pred_label}' ({original_pred_prob.item():.4f})\")\n",
        "print(f\"Adversarial Image Prediction (Model 2): '{adv_pred_label}' ({adv_pred_prob.item():.4f})\")\n",
        "print(\"-\" * 20)\n",
        "print(\"Files saved in Colab environment:\")\n",
        "print(f\"  Original Image:       {ORIGINAL_IMAGE_SAVE_PATH}\")\n",
        "print(f\"  Noise Visualization:  {NOISE_IMAGE_SAVE_PATH}\")\n",
        "print(f\"  Adversarial Image:    {ADVERSARIAL_IMAGE_SAVE_PATH}\")\n",
        "print(\"-\" * 20)\n",
        "print(\"You can also view/download these files from the file browser panel on the left in Colab.\")\n",
        "print(\"\\n--- Tutorial Finished ---\")"
      ],
      "metadata": {
        "id": "XT8ncfjddAxs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ae3c8bf-953b-432b-a10d-f4d06730108a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IpZzm13OeP8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}