{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4a7f46a89b0457baccd045e9ed5fbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16a8c2e79e00472ab14e2b3ce082862e",
              "IPY_MODEL_4ca1b4822f2243669ba52633a5255978",
              "IPY_MODEL_272eb3d3dc34483a9b867ddb10c51313"
            ],
            "layout": "IPY_MODEL_f464e64ee7ed4c93bada3dd6bcf6877c"
          }
        },
        "16a8c2e79e00472ab14e2b3ce082862e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04421f78a65d4651b36f35dc297b6780",
            "placeholder": "​",
            "style": "IPY_MODEL_a92cb388bdf04769bf6462ff44691b64",
            "value": "Map: 100%"
          }
        },
        "4ca1b4822f2243669ba52633a5255978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6faa48cb9234c1b865fb1897cd81f9b",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f3bc1d515e54300b5dac93c90455b34",
            "value": 200
          }
        },
        "272eb3d3dc34483a9b867ddb10c51313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5edc9da6d2e46b78bbdbce59eb1af3c",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f227f06bb74485b9e8ffdcd9f52161",
            "value": " 200/200 [00:00&lt;00:00, 1693.79 examples/s]"
          }
        },
        "f464e64ee7ed4c93bada3dd6bcf6877c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04421f78a65d4651b36f35dc297b6780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92cb388bdf04769bf6462ff44691b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6faa48cb9234c1b865fb1897cd81f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f3bc1d515e54300b5dac93c90455b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5edc9da6d2e46b78bbdbce59eb1af3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f227f06bb74485b9e8ffdcd9f52161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rbzVScESgT0"
      },
      "outputs": [],
      "source": [
        "# === Step 1: installing libaries ===\n",
        "# Install necessary libraries\n",
        "!pip install transformers[torch] datasets scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 2: Load Dataset ===\n",
        "from datasets import load_dataset\n",
        "import pandas as pd # Import pandas for better display if needed\n",
        "\n",
        "# Load the sst2 dataset\n",
        "dataset = load_dataset(\"sst2\")\n",
        "\n",
        "# Use smaller subsets for quicker demo (optional, but recommended for speed)\n",
        "train_sample_size = 1000\n",
        "validation_sample_size = 200\n",
        "test_sample_size = 872 # Use the full validation set as test set\n",
        "\n",
        "# Shuffle and select subsets\n",
        "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(train_sample_size))\n",
        "small_validation_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(validation_sample_size))\n",
        "# Use the original validation set for final testing in this example\n",
        "small_test_dataset = dataset[\"validation\"].select(range(test_sample_size))\n",
        "\n",
        "print(\"\\nDataset loaded and split:\")\n",
        "print(f\"Training examples: {len(small_train_dataset)}\")\n",
        "print(f\"Validation examples: {len(small_validation_dataset)}\")\n",
        "print(f\"Test examples: {len(small_test_dataset)}\")\n",
        "print(\"\\nExample Training Data Point:\")\n",
        "# Displaying using pandas for potentially nicer formatting\n",
        "display(pd.DataFrame([small_train_dataset[0]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "8UuuH-roXmqS",
        "outputId": "7f000dd3-c6b1-4692-8c02-c6e8d4ba0bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset loaded and split:\n",
            "Training examples: 1000\n",
            "Validation examples: 200\n",
            "Test examples: 872\n",
            "\n",
            "Example Training Data Point:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     idx                                           sentence  label\n",
              "0  32326  klein , charming in comedies like american pie...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f45af336-f009-4a76-8eb7-61117db37a03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32326</td>\n",
              "      <td>klein , charming in comedies like american pie...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f45af336-f009-4a76-8eb7-61117db37a03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f45af336-f009-4a76-8eb7-61117db37a03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f45af336-f009-4a76-8eb7-61117db37a03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 32326,\n        \"max\": 32326,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          32326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"klein , charming in comedies like american pie and dead-on in election , \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 3: Preprocess Data (Tokenization) ===\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the base model checkpoint\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "\n",
        "# Load the tokenizer associated with the base model\n",
        "# We will reuse this 'tokenizer' object later for the prediction pipeline\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "print(f\"\\nTokenizer loaded from '{model_checkpoint}'.\")\n",
        "\n",
        "# Function to tokenize the sentences\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], truncation=True, padding=True)\n",
        "\n",
        "# Apply the tokenization function\n",
        "print(\"Tokenizing datasets...\")\n",
        "tokenized_train_dataset = small_train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_validation_dataset = small_validation_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test_dataset = small_test_dataset.map(preprocess_function, batched=True)\n",
        "print(\"Tokenization complete.\")\n",
        "print(\"\\nExample of tokenized data keys:\")\n",
        "print(tokenized_train_dataset[0].keys()) # Show the new keys added by tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "c4a7f46a89b0457baccd045e9ed5fbd7",
            "16a8c2e79e00472ab14e2b3ce082862e",
            "4ca1b4822f2243669ba52633a5255978",
            "272eb3d3dc34483a9b867ddb10c51313",
            "f464e64ee7ed4c93bada3dd6bcf6877c",
            "04421f78a65d4651b36f35dc297b6780",
            "a92cb388bdf04769bf6462ff44691b64",
            "a6faa48cb9234c1b865fb1897cd81f9b",
            "1f3bc1d515e54300b5dac93c90455b34",
            "a5edc9da6d2e46b78bbdbce59eb1af3c",
            "b0f227f06bb74485b9e8ffdcd9f52161"
          ]
        },
        "id": "tsz70NsoXouC",
        "outputId": "518003f4-bbdf-4381-b2f9-02cbcff69712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenizer loaded from 'distilbert-base-uncased'.\n",
            "Tokenizing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4a7f46a89b0457baccd045e9ed5fbd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n",
            "\n",
            "Example of tokenized data keys:\n",
            "dict_keys(['idx', 'sentence', 'label', 'input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 4: Load Pre-trained Model ===\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch # Ensure torch is imported\n",
        "\n",
        "# Load the DistilBERT model configured for sequence classification with 2 labels\n",
        "# The classification head weights will be random initially.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
        "print(f\"\\nPre-trained model '{model_checkpoint}' loaded for sequence classification.\")\n",
        "# Check if GPU is available and move model if needed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Model moved to device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNo67yw3XqCD",
        "outputId": "2d74629d-f04c-4332-fee4-1ab9ab822993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pre-trained model 'distilbert-base-uncased' loaded for sequence classification.\n",
            "Model moved to device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 5: Define Training Settings and Evaluation Metric ===\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define output directory\n",
        "output_dir = \"misleading-content-classifier\"\n",
        "\n",
        "# Configure training arguments (Corrected)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    eval_strategy=\"epoch\",             # Corrected from evaluation_strategy\n",
        "    num_train_epochs=1,                # Keep low for demo\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",             # Save checkpoint at the end of each epoch\n",
        "    load_best_model_at_end=True,       # Load the best checkpoint at the end\n",
        "    metric_for_best_model=\"accuracy\",  # Specify metric to determine the best model\n",
        "    greater_is_better=True,            # Higher accuracy is better\n",
        "    report_to=\"none\",                  # Disable wandb integration\n",
        ")\n",
        "print(\"\\nTraining arguments defined.\")\n",
        "\n",
        "# Define the function to compute accuracy\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "print(\"Metrics function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojAgd58TXsfb",
        "outputId": "5c800700-4146-4563-f549-16502c542cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training arguments defined.\n",
            "Metrics function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 6: Train the Model (Fine-tuning) ===\n",
        "\n",
        "# Create the Trainer instance (Corrected: removed deprecated tokenizer argument)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_validation_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    # tokenizer=tokenizer, # Argument deprecated and removed\n",
        ")\n",
        "print(\"\\nTrainer initialized. Starting training...\")\n",
        "\n",
        "# Start training\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nTRAINING COMPLETE!\")\n",
        "# Log some training metrics\n",
        "metrics = train_result.metrics\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ISwmlX3kXuwB",
        "outputId": "24fe025e-d41e-4e48-a0f7-5221c94bdb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trainer initialized. Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:13, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.668500</td>\n",
              "      <td>0.384761</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAINING COMPLETE!\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =    12770GF\n",
            "  train_loss               =     0.6244\n",
            "  train_runtime            = 0:00:14.59\n",
            "  train_samples_per_second =     68.527\n",
            "  train_steps_per_second   =      4.317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 7: Evaluate the Trained Model ===\n",
        "\n",
        "print(\"\\nEVALUATING MODEL ON TEST DATA...\")\n",
        "# Use the test dataset for final evaluation\n",
        "eval_results = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
        "\n",
        "print(\"\\n--- Evaluation Results on Test Set ---\")\n",
        "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
        "trainer.log_metrics(\"eval\", eval_results)\n",
        "trainer.save_metrics(\"eval\", eval_results)\n",
        "print(\"(Remember: Label 0 -> 'Potentially Misleading', Label 1 -> 'Potentially Credible')\")\n",
        "\n",
        "\n",
        "# === Step 7.5: Find the Best Model Path ===\n",
        "import os\n",
        "\n",
        "# Find the path to the best model checkpoint saved by the Trainer\n",
        "best_model_checkpoint_path = trainer.state.best_model_checkpoint\n",
        "\n",
        "if best_model_checkpoint_path and os.path.isdir(best_model_checkpoint_path):\n",
        "    print(f\"\\nBest model checkpoint identified at: {best_model_checkpoint_path}\")\n",
        "    model_load_path = best_model_checkpoint_path\n",
        "else:\n",
        "    print(f\"\\nWarning: Could not find best model checkpoint path in trainer state: {best_model_checkpoint_path}\")\n",
        "    print(f\"Attempting to load from base output directory: {output_dir}\")\n",
        "    try:\n",
        "        print(f\"Contents of '{output_dir}': {os.listdir(output_dir)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Output directory '{output_dir}' not found.\")\n",
        "    model_load_path = output_dir # Fallback\n",
        "\n",
        "print(f\"Using path for loading fine-tuned model: {model_load_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "IYE5la8yTDLi",
        "outputId": "0bfd1d8b-8055-47e8-e606-45d56939baa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EVALUATING MODEL ON TEST DATA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation Results on Test Set ---\n",
            "Accuracy: 0.8394\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_accuracy           =     0.8394\n",
            "  eval_loss               =     0.4041\n",
            "  eval_runtime            = 0:00:01.63\n",
            "  eval_samples_per_second =    532.703\n",
            "  eval_steps_per_second   =     33.599\n",
            "(Remember: Label 0 -> 'Potentially Misleading', Label 1 -> 'Potentially Credible')\n",
            "\n",
            "Best model checkpoint identified at: misleading-content-classifier/checkpoint-63\n",
            "Using path for loading fine-tuned model: misleading-content-classifier/checkpoint-63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 8: Use the Trained Model for Predictions (Corrected) ===\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"\\n--- Setting up Prediction Pipeline ---\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Load the fine-tuned MODEL explicitly from the best checkpoint path\n",
        "        print(f\"Loading fine-tuned model from: {model_load_path}\")\n",
        "        loaded_fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(model_load_path)\n",
        "        loaded_fine_tuned_model.to(device)  # Ensure model is on the correct device\n",
        "        print(\"Fine-tuned model loaded successfully.\")\n",
        "\n",
        "        # Reuse the original tokenizer loaded earlier\n",
        "        print(f\"Reusing the original tokenizer from: '{model_checkpoint}'\")\n",
        "        prediction_tokenizer = tokenizer  # Ensure 'tokenizer' is properly defined earlier\n",
        "\n",
        "        # Create the pipeline\n",
        "        classifier_pipeline = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=loaded_fine_tuned_model,\n",
        "            tokenizer=prediction_tokenizer,\n",
        "            device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
        "        )\n",
        "        print(\"Prediction pipeline created successfully.\")\n",
        "\n",
        "        # Define label mappings\n",
        "        label_map = {\n",
        "            \"LABEL_0\": \"Potentially Misleading/Unreliable\",\n",
        "            \"LABEL_1\": \"Potentially Credible/Reliable\"\n",
        "        }\n",
        "\n",
        "        # Example sentences\n",
        "        test_sentences = [\n",
        "            \"This scientific study shows clear evidence for the new treatment.\",\n",
        "            \"Everyone knows that eating pizza cures the common cold!\",\n",
        "            \"The report cites multiple anonymous sources with conflicting stories.\",\n",
        "            \"The politician made vague promises during the speech.\",\n",
        "            \"An amazing film, truly inspiring and well-acted.\",\n",
        "            \"A terrible waste of time, completely boring and predictable.\"\n",
        "        ]\n",
        "\n",
        "        print(\"\\n--- Making Predictions on New Sentences ---\")\n",
        "        for sentence in test_sentences:\n",
        "            result = classifier_pipeline(sentence)[0]\n",
        "            predicted_label_name = label_map.get(result['label'], result['label'])\n",
        "            print(f\"Sentence: \\\"{sentence}\\\"\")\n",
        "            print(f\"Prediction: {predicted_label_name} (Score: {result['score']:.4f})\")\n",
        "            print(\"-\" * 20)\n",
        "\n",
        "        # User input for live testing\n",
        "        print(\"\\n=== Try your own sentence! ===\")\n",
        "        my_sentence = input(\"Enter a sentence to classify: \")\n",
        "        if my_sentence:\n",
        "            my_result = classifier_pipeline(my_sentence)[0]\n",
        "            my_predicted_label = label_map.get(my_result['label'], my_result['label'])\n",
        "            print(f\"Prediction: {my_predicted_label} (Score: {my_result['score']:.4f})\")\n",
        "        else:\n",
        "            print(\"No input provided.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- An error occurred during prediction setup or execution ---\")\n",
        "        print(f\"Model load path attempted: {model_load_path}\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"\\nPlease check the following:\")\n",
        "        print(\"1. Training completed without errors.\")\n",
        "        print(f\"2. The path '{model_load_path}' exists and contains model files (like config.json, model weights).\")\n",
        "        print(f\"3. The original tokenizer '{model_checkpoint}' is valid.\")\n",
        "        print(\"\\n--- End of Script ---\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tawyUlqoVrqv",
        "outputId": "ec9f546c-786e-46d5-cb90-ebd2f420c116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up Prediction Pipeline ---\n",
            "Loading fine-tuned model from: misleading-content-classifier/checkpoint-63\n",
            "Fine-tuned model loaded successfully.\n",
            "Reusing the original tokenizer from: 'distilbert-base-uncased'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction pipeline created successfully.\n",
            "\n",
            "--- Making Predictions on New Sentences ---\n",
            "Sentence: \"This scientific study shows clear evidence for the new treatment.\"\n",
            "Prediction: Potentially Credible/Reliable (Score: 0.7573)\n",
            "--------------------\n",
            "Sentence: \"Everyone knows that eating pizza cures the common cold!\"\n",
            "Prediction: Potentially Misleading/Unreliable (Score: 0.6811)\n",
            "--------------------\n",
            "Sentence: \"The report cites multiple anonymous sources with conflicting stories.\"\n",
            "Prediction: Potentially Misleading/Unreliable (Score: 0.7144)\n",
            "--------------------\n",
            "Sentence: \"The politician made vague promises during the speech.\"\n",
            "Prediction: Potentially Misleading/Unreliable (Score: 0.7779)\n",
            "--------------------\n",
            "Sentence: \"An amazing film, truly inspiring and well-acted.\"\n",
            "Prediction: Potentially Credible/Reliable (Score: 0.9028)\n",
            "--------------------\n",
            "Sentence: \"A terrible waste of time, completely boring and predictable.\"\n",
            "Prediction: Potentially Misleading/Unreliable (Score: 0.8255)\n",
            "--------------------\n",
            "\n",
            "=== Try your own sentence! ===\n",
            "Enter a sentence to classify: On August 20, 2022, a TikTok video was posted, claiming that Disney World was going to lower the drinking age to 18. It was stated that Disney World was battling the Florida government in court to get a resort exemption, which would allow anyone 18 and older to drink on property. The TikTok video acquired millions of views in just a couple days. This story was also posted on facebook, instagram, and Twitter. Shortly after, the story made it on ABC 10 News.\n",
            "Prediction: Potentially Misleading/Unreliable (Score: 0.5844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oPORa99dWpAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}