{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
        "import warnings\n",
        "\n",
        "# Suppress all warnings (optional)\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "id": "byfxW_e8omOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Explicitly set pad_token_id to eos_token_id\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# Initialize the text generation pipeline\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGHHShJVon95",
        "outputId": "695a188e-8066-404f-f889-cd8cd7904211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optional if using colab\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urywD2XyopIw",
        "outputId": "7faa9b02-8a31-4dcb-c02c-cb39e8168f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_word():\n",
        "    \"\"\"Generates a random word using GPT-2.\"\"\"\n",
        "    prompt = \"Think of a single word: \"\n",
        "    output = generator(prompt, max_length=10, do_sample=True, temperature=0.8, truncation=True)  # Explicit truncation\n",
        "    word = output[0]['generated_text'].replace(prompt, '').strip().split()[0]  # Extract the first word\n",
        "    return word\n",
        "\n",
        "def generate_clue(word):\n",
        "    \"\"\"Generates a clue for the given word using GPT-2.\"\"\"\n",
        "    prompt = f\"Give a hint about {word}: \"\n",
        "    output = generator(prompt, max_length=30, do_sample=True, temperature=0.7, truncation=True)  # Explicit truncation\n",
        "    clue = output[0]['generated_text'].replace(prompt, '').strip()\n",
        "    return clue\n",
        "\n",
        "def play_game():\n",
        "    print(\"Welcome to the AI Clue Game!\\n\")\n",
        "    score = 0\n",
        "    rounds = 3\n",
        "\n",
        "    for i in range(rounds):\n",
        "        correct_answer = generate_word()\n",
        "        print(f\"Round {i+1}:\")\n",
        "        clue = generate_clue(correct_answer)\n",
        "        print(\"Clue:\", clue)\n",
        "        user_guess = input(\"Your guess: \")\n",
        "\n",
        "        if user_guess.lower() == correct_answer.lower():\n",
        "            print(\"Correct! You earned 1 point.\\n\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"Wrong! The correct answer was: {correct_answer}\\n\")\n",
        "\n",
        "    print(f\"Game Over! Your final score: {score}/{rounds}\")"
      ],
      "metadata": {
        "id": "3oCc6PaGoOda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    play_game()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YmOfdpKoYGB",
        "outputId": "77e84835-0d2e-4887-a9a0-60e5f211cd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AI Clue Game!\n",
            "\n",
            "Round 1:\n",
            "Clue: A. The first thing you'll do is find your character's portrait and choose the right portrait.\n",
            "Your guess: hi\n",
            "Wrong! The correct answer was: you'll\n",
            "\n",
            "Round 2:\n",
            "Clue: this one is for you guys. I am really going to go back and do a lot of things that make\n",
            "Your guess: by\n",
            "Wrong! The correct answer was: -\n",
            "\n",
            "Round 3:\n",
            "Clue: \", the only thing they do is jump on the line and make a nice mess.\n",
            "\n",
            "1.2\n",
            "Your guess: exit\n",
            "Wrong! The correct answer was: \"\n",
            "\n",
            "Game Over! Your final score: 0/3\n"
          ]
        }
      ]
    }
  ]
}